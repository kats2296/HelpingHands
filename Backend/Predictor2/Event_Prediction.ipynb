{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "dataset = pd.read_csv(\"helpinghands_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>STATNAME</th>\n",
       "      <th>STATCD</th>\n",
       "      <th>DISTNAME</th>\n",
       "      <th>DISTCD</th>\n",
       "      <th>EVENT_NAME</th>\n",
       "      <th>EVENT_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>28</td>\n",
       "      <td>PRAKASAM</td>\n",
       "      <td>2818</td>\n",
       "      <td>poverty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>18</td>\n",
       "      <td>UDALGURI</td>\n",
       "      <td>1826</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>PUNJAB</td>\n",
       "      <td>3</td>\n",
       "      <td>HOSHIARPUR</td>\n",
       "      <td>305</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>TELANGANA</td>\n",
       "      <td>36</td>\n",
       "      <td>NALGONDA</td>\n",
       "      <td>3608</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>KARNATAKA</td>\n",
       "      <td>29</td>\n",
       "      <td>KODAGU</td>\n",
       "      <td>2925</td>\n",
       "      <td>donations</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH        STATNAME  STATCD    DISTNAME  DISTCD EVENT_NAME  \\\n",
       "0  2013      1  ANDHRA PRADESH      28    PRAKASAM    2818    poverty   \n",
       "1  2013      8           ASSAM      18    UDALGURI    1826  education   \n",
       "2  2013      9          PUNJAB       3  HOSHIARPUR     305  education   \n",
       "3  2013      8       TELANGANA      36    NALGONDA    3608  education   \n",
       "4  2013      4       KARNATAKA      29      KODAGU    2925  donations   \n",
       "\n",
       "   EVENT_CODE  \n",
       "0           1  \n",
       "1           3  \n",
       "2           3  \n",
       "3           3  \n",
       "4           4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR          0\n",
       "MONTH         0\n",
       "STATNAME      0\n",
       "STATCD        0\n",
       "DISTNAME      0\n",
       "DISTCD        0\n",
       "EVENT_NAME    0\n",
       "EVENT_CODE    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Independent features\n",
    "X = dataset.iloc[:, [1,5]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1, 2818],\n",
       "       [   8, 1826],\n",
       "       [   9,  305],\n",
       "       ...,\n",
       "       [   2, 1202],\n",
       "       [   4, 2811],\n",
       "       [   2, 1005]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 2)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dependent variable vector\n",
    "y = dataset.iloc[:, 7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 3, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode categorical data\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoderEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_data(X):\n",
    "    X = onehotencoder.fit_transform(X).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(data=X)\n",
    "df_y = pd.DataFrame(data=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1\n",
       "0  1  2818\n",
       "1  8  1826\n",
       "2  9   305\n",
       "3  8  3608\n",
       "4  4  2925"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 2)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = encode_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 112)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kats/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataset into training and test set\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, test_size=0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 112)\n",
      "(16000, 112)\n",
      "(64000,)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]), array([1, 4, 1, ..., 1, 1, 1]), array([1, 2, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test , y_train , y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "def get_scaled_data(X_train, X_test):\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = get_scaled_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31017658, -0.30481935, -0.31087222, ..., -0.09858266,\n",
       "        -0.10121517, -0.09954767],\n",
       "       [-0.31017658, -0.30481935, -0.31087222, ..., -0.09858266,\n",
       "        -0.10121517, -0.09954767],\n",
       "       [-0.31017658, -0.30481935, -0.31087222, ..., -0.09858266,\n",
       "        -0.10121517, -0.09954767],\n",
       "       ...,\n",
       "       [-0.31017658, -0.30481935,  3.21675578, ..., -0.09858266,\n",
       "        -0.10121517, -0.09954767],\n",
       "       [-0.31017658, -0.30481935, -0.31087222, ..., -0.09858266,\n",
       "        -0.10121517, -0.09954767],\n",
       "       [-0.31017658, -0.30481935, -0.31087222, ..., -0.09858266,\n",
       "        -0.10121517, 10.04543817]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting KNN classifier to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(X_train, y_train):\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=8, metric='minkowski' , p=2)\n",
    "    model_knn.fit(X_train , y_train)\n",
    "    return model_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_knn = fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 112)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "print y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_model_5.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "filename = 'knn_model_5.pkl'\n",
    "joblib.dump(model_knn, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 65.99 %\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "score = loaded_model.score(X_test, y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print X_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesing on 2017 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2016 = pd.read_csv(\"dataset_2012.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2016_data = X_2016.iloc[:, [1,5]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2016_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1000\n",
    "def make_prediction_data() :\n",
    "    count=0\n",
    "    for row in range (0, 10000, k) :\n",
    "        x_write = []\n",
    "        count+=1\n",
    "        X = X_2016_data[row:row+k, :]\n",
    "        for i in xrange(k):   \n",
    "            x_write.append(list(X_2016.iloc[i, :].values))\n",
    "        X_encoded = encode_data(X)\n",
    "        _ , X_test_2016 = get_scaled_data(X_train, X_encoded)\n",
    "        predict_data(X_test_2016, x_write, k)\n",
    "\n",
    "\n",
    "event_dict = {1: 'poverty', 2: 'health_care', 3: 'education', 4: 'donations'}\n",
    "\n",
    "def predict_data(x_test, x_file, k) :\n",
    "    \n",
    "    y_pred = model_knn.predict(x_test)\n",
    "        \n",
    "    for i in range(k) :\n",
    "        event = event_dict[y_pred[i]]\n",
    "        x_file[i].append(event)\n",
    "        x_file[i].append(y_pred[i])\n",
    "        write_to_file(x_file[i])\n",
    "\n",
    "import csv\n",
    "def write_to_file(row) :\n",
    "        with open('helpinghands_dataset.csv', 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(row)\n",
    "        csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_prediction_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def show_prediction_info():\n",
    "    pd.read_csv(\"helpinghands_dataset.csv\")\n",
    "    X = dataset.iloc[:, [1,5]].values\n",
    "    y = dataset.iloc[:, 7].values\n",
    "    print X.shape\n",
    "    print y.shape\n",
    "    X = encode_data(X)\n",
    "    X_train , X_test , y_train , y_test = train_test_split(X, y, test_size=0.2 , random_state=0)\n",
    "    print X_train.shape\n",
    "    print X_test.shape\n",
    "    print y_train.shape\n",
    "    print y_test.shape\n",
    "    X_train, X_test = get_scaled_data(X_train, X_test)\n",
    "    model = fit_model(X_train, y_train)\n",
    "    y_pred = model_knn.predict(X_test)\n",
    "    score = loaded_model.score(X_test, y_test)\n",
    "    print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_prediction_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting SVM classifier to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear' , random_state=0)\n",
    "classifier.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "filename = 'svm_model.pkl'\n",
    "joblib.dump(classifier, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 67.81 %\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "score = loaded_model.score(X_test, y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Decision Tree classifier to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion='entropy' , random_state=0)\n",
    "classifier.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "filename = 'decision_tree_model.pkl'\n",
    "joblib.dump(classifier, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 67.74 %\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "score = loaded_model.score(X_test, y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Random Forest classifier to the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=10 , criterion='entropy' , random_state=0)\n",
    "classifier.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "filename = 'rf_model.pkl'\n",
    "joblib.dump(classifier, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 67.69 %\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "score = loaded_model.score(X_test, y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Naive Bayes classifier to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_model.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "filename = 'nb_model.pkl'\n",
    "joblib.dump(classifier, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 30.36 %\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "score = loaded_model.score(X_test, y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
