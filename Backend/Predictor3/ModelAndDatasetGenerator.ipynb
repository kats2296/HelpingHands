{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DummyDataBuilderEncoded:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "        self.events = ['poverty', 'health_care', 'education', 'donations']\n",
    "        self.event_codes = [1, 2, 3, 4]\n",
    "        self.event_dict = {1: 'poverty', 2: 'health_care', 3: 'education', 4: 'donations'}\n",
    "\n",
    "    def generate_data(self):\n",
    "            for i in xrange(10000):\n",
    "                year = 2010\n",
    "                self.organise_data_from_csv(year)\n",
    "\n",
    "    def organise_data_from_csv(self, year):\n",
    "        states_districts = pd.read_csv(\"important_districts.csv\").iloc[:, 1: 5]\n",
    "        random_row = states_districts.sample(1)\n",
    "        state = ''.join(random_row['STATNAME'].values)\n",
    "        state_code = int(random_row['STATCD'])\n",
    "        district = ''.join(random_row['DISTNAME'].values)\n",
    "        district_code = int(random_row['DISTCD'])\n",
    "\n",
    "        month = random.choice(self.months)\n",
    "        event_code = random.choice(self.event_codes)\n",
    "        event = self.event_dict[event_code]\n",
    "\n",
    "        self.write_data_to_csv(year, month, state, state_code, district, district_code, event, event_code)\n",
    "\n",
    "    @staticmethod\n",
    "    def write_data_to_csv(year, month, state, state_code, district, district_code, event, event_code):\n",
    "\n",
    "        row = [year, month, state, state_code, district, district_code, event, event_code]\n",
    "        with open('random_dataset_2010.csv', 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(row)\n",
    "        csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### using important distriscts only to generate random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DummyDataBuilderEncoded().generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now a random dataset for year 2010 is generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "dataset = pd.read_csv(\"random_dataset_2010.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>STATNAME</th>\n",
       "      <th>STATCD</th>\n",
       "      <th>DISTNAME</th>\n",
       "      <th>DISTCD</th>\n",
       "      <th>EVENT_NAME</th>\n",
       "      <th>EVENT_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>9</td>\n",
       "      <td>KUSHINAGAR</td>\n",
       "      <td>959</td>\n",
       "      <td>donations</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>CHANDIGARH</td>\n",
       "      <td>4</td>\n",
       "      <td>CHANDIGARH</td>\n",
       "      <td>401</td>\n",
       "      <td>health_care</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>JHARKHAND</td>\n",
       "      <td>20</td>\n",
       "      <td>GODDA</td>\n",
       "      <td>2008</td>\n",
       "      <td>health_care</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>23</td>\n",
       "      <td>SIDHI</td>\n",
       "      <td>2317</td>\n",
       "      <td>health_care</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>23</td>\n",
       "      <td>ALIRAJPUR</td>\n",
       "      <td>2349</td>\n",
       "      <td>donations</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH        STATNAME  STATCD    DISTNAME  DISTCD   EVENT_NAME  \\\n",
       "0  2010      5   UTTAR PRADESH       9  KUSHINAGAR     959    donations   \n",
       "1  2010      7      CHANDIGARH       4  CHANDIGARH     401  health_care   \n",
       "2  2010      6       JHARKHAND      20       GODDA    2008  health_care   \n",
       "3  2010      3  MADHYA PRADESH      23       SIDHI    2317  health_care   \n",
       "4  2010      2  MADHYA PRADESH      23   ALIRAJPUR    2349    donations   \n",
       "\n",
       "   EVENT_CODE  \n",
       "0           4  \n",
       "1           2  \n",
       "2           2  \n",
       "3           2  \n",
       "4           4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Independent features - month and district code\n",
    "X = dataset.iloc[:, [1,5]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5,  959],\n",
       "       [   7,  401],\n",
       "       [   6, 2008],\n",
       "       [   3, 2317],\n",
       "       [   2, 2349]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dependent variable vector - event code\n",
    "y = dataset.iloc[:, 7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 2, 2, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode categorical data\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_data(X):\n",
    "    X = onehotencoder.fit_transform(X).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 112)\n"
     ]
    }
   ],
   "source": [
    "X = encode_data(X)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, test_size=0.25 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 112)\n",
      "(2500, 112)\n",
      "(7500,)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "def get_scaled_data(X_train, X_test):\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = get_scaled_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 112) (2500, 112)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting KNN classifier to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(X_train, y_train):\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=8, metric='minkowski' , p=2)\n",
    "    model_knn.fit(X_train , y_train)\n",
    "    return model_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_knn = fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "print y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the model\n",
    "from sklearn.externals import joblib\n",
    "filename = 'knn_model_trained_on_2010.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_knn, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = loaded_model.score(X_test, y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we have a model ready that is trained on 2010 random dataset.\n",
    "# After this , for every next year event code and event name will be predicted using the previously learned model_knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for making datasets for each year without events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DummyDataBuilderEncodedWithoutEvent:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.years = [2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "        self.months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "    def generate_data(self):\n",
    "        for year in self.years:\n",
    "            filename = \"dataset_\"+str(year)+\".csv\"\n",
    "            row = [\"YEAR\", \"MONTH\", \"STATNAME\", \"STATCD\", \"DISTNAME\", \"DISTCD\"]\n",
    "\n",
    "            with open(filename, 'a') as csvFile:\n",
    "                writer = csv.writer(csvFile)\n",
    "                writer.writerow(row)\n",
    "            csvFile.close()\n",
    "            for i in xrange(10000):\n",
    "                self.organise_data_from_csv(year, filename)\n",
    "\n",
    "    def organise_data_from_csv(self, year, filename):\n",
    "        states_districts = pd.read_csv(\"important_districts.csv\").iloc[:, 1: 5]\n",
    "        random_row = states_districts.sample(1)\n",
    "        state = ''.join(random_row['STATNAME'].values)\n",
    "        state_code = int(random_row['STATCD'])\n",
    "        district = ''.join(random_row['DISTNAME'].values)\n",
    "        district_code = int(random_row['DISTCD'])\n",
    "\n",
    "        month = random.choice(self.months)\n",
    "\n",
    "        self.write_data_to_csv(year, month, state, state_code, district, district_code, filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def write_data_to_csv(year, month, state, state_code, district, district_code, filename):\n",
    "\n",
    "        row = [year, month, state, state_code, district, district_code]\n",
    "\n",
    "        with open(filename, 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(row)\n",
    "\n",
    "        csvFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DummyDataBuilderEncodedWithoutEvent().generate_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we have datasets for year 2011 to 2017 but without corresponding events\n",
    "# events of these years will be predicted using learned models and predicted rows will be added to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### predicting and genrating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class PredictGenerate():\n",
    "    def __init__(self):\n",
    "        self.years = [2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "        self.sc_X = StandardScaler()\n",
    "        self.onehotencoder = OneHotEncoder(categorical_features = [0,1])\n",
    "        self.event_dict = {1: 'poverty', 2: 'health_care', 3: 'education', 4: 'donations'}\n",
    "        self.model_knn = joblib.load('knn_model_trained_on_2010.pkl')\n",
    "        \n",
    "    \n",
    "    def set_up_data(self):\n",
    "        for year in self.years:\n",
    "            filename = \"dataset_\"+str(year)+\".csv\"\n",
    "            df = pd.read_csv(filename)\n",
    "            X_data = df.iloc[:, [1,5]].values\n",
    "            self.make_prediction_data(df, X_data, year)\n",
    "\n",
    "    def make_prediction_data(self, df, X_data, year) :\n",
    "        k = 1000\n",
    "        for row in range (0, 10000, k) :\n",
    "            x_write = []\n",
    "            X = X_data[row:row+k, :]\n",
    "            for i in xrange(k):   \n",
    "                x_write.append(list(df.iloc[i, :].values))\n",
    "                \n",
    "            X_encoded = self.encode_data(X)\n",
    "            X_test = self.get_scaled_test_data(X_encoded)\n",
    "            self.predict_data(X_test, x_write, k, year)\n",
    "            self.make_new_model(year)\n",
    "            \n",
    "    def predict_data(self, x_test, x_file, k, year) :\n",
    "        y_pred = self.model_knn.predict(x_test)\n",
    "        for i in range(k) :\n",
    "            event = self.event_dict[y_pred[i]]\n",
    "            x_file[i].append(event)\n",
    "            x_file[i].append(y_pred[i])\n",
    "            self.write_to_file(x_file[i], year)\n",
    "            \n",
    "    def write_to_file(self, row, year) :\n",
    "        with open('knn_dataset.csv', 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(row)\n",
    "        csvFile.close()\n",
    "        \n",
    "    \n",
    "    def make_new_model(self, year):\n",
    "        dataset = pd.read_csv(\"knn_dataset.csv\")\n",
    "        X = dataset.iloc[:, [1,5]].values\n",
    "        y = dataset.iloc[:, 7].values\n",
    "        X = self.encode_data(X)\n",
    "        X_train , X_test , y_train , y_test = train_test_split(X, y, test_size=0.25 , random_state=0)\n",
    "        X_train, X_test = self.get_scaled_data(X_train, X_test)\n",
    "        self.model_knn = self.fit_model(X_train, y_train)\n",
    "        filename = 'knn_model.pkl'\n",
    "        joblib.dump(self.model_knn, filename)\n",
    "        score = self.model_knn.score(X_test, y_test)\n",
    "        print(\"Test score for year {} : {}%\".format(year, 100 * score))\n",
    "\n",
    "    def fit_model(seld, X_train, y_train):\n",
    "        model_knn = KNeighborsClassifier(n_neighbors=8, metric='minkowski' , p=2)\n",
    "        model_knn.fit(X_train , y_train)\n",
    "        return model_knn\n",
    "        \n",
    "    def get_scaled_test_data(self, X_test):\n",
    "        X_test = self.sc_X.fit_transform(X_test)\n",
    "        return X_test\n",
    "\n",
    "    def get_scaled_data(self, X_train, X_test):\n",
    "        X_train = self.sc_X.fit_transform(X_train)\n",
    "        X_test = self.sc_X.fit_transform(X_test)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def encode_data(self, X):\n",
    "        X = self.onehotencoder.fit_transform(X).toarray()\n",
    "        return X\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for year 2011 : 31.1636363636%\n",
      "Test score for year 2011 : 29.3333333333%\n",
      "Test score for year 2011 : 27.2923076923%\n",
      "Test score for year 2011 : 28.5428571429%\n",
      "Test score for year 2011 : 26.9333333333%\n",
      "Test score for year 2011 : 26.625%\n",
      "Test score for year 2011 : 26.9176470588%\n",
      "Test score for year 2011 : 27.5777777778%\n",
      "Test score for year 2011 : 26.8631578947%\n",
      "Test score for year 2011 : 27.28%\n",
      "Test score for year 2012 : 30.6285714286%\n",
      "Test score for year 2012 : 29.8363636364%\n",
      "Test score for year 2012 : 28.9565217391%\n",
      "Test score for year 2012 : 28.9666666667%\n",
      "Test score for year 2012 : 29.568%\n",
      "Test score for year 2012 : 29.0153846154%\n",
      "Test score for year 2012 : 29.5407407407%\n",
      "Test score for year 2012 : 29.9142857143%\n",
      "Test score for year 2012 : 30.4413793103%\n",
      "Test score for year 2012 : 30.92%\n",
      "Test score for year 2013 : 31.7419354839%\n",
      "Test score for year 2013 : 32.2625%\n",
      "Test score for year 2013 : 31.9151515152%\n",
      "Test score for year 2013 : 31.8352941176%\n",
      "Test score for year 2013 : 32.5371428571%\n",
      "Test score for year 2013 : 33.2555555556%\n",
      "Test score for year 2013 : 33.3297297297%\n",
      "Test score for year 2013 : 33.9052631579%\n",
      "Test score for year 2013 : 34.1435897436%\n",
      "Test score for year 2013 : 34.03%\n",
      "Test score for year 2014 : 35.5414634146%\n",
      "Test score for year 2014 : 35.7047619048%\n",
      "Test score for year 2014 : 36.8837209302%\n",
      "Test score for year 2014 : 35.9454545455%\n",
      "Test score for year 2014 : 37.2%\n",
      "Test score for year 2014 : 37.7652173913%\n",
      "Test score for year 2014 : 38.3574468085%\n",
      "Test score for year 2014 : 38.3666666667%\n",
      "Test score for year 2014 : 39.0857142857%\n",
      "Test score for year 2014 : 39.296%\n",
      "Test score for year 2015 : 39.8901960784%\n",
      "Test score for year 2015 : 40.3%\n",
      "Test score for year 2015 : 40.5509433962%\n",
      "Test score for year 2015 : 41.6444444444%\n",
      "Test score for year 2015 : 42.1454545455%\n",
      "Test score for year 2015 : 42.4785714286%\n",
      "Test score for year 2015 : 42.8280701754%\n",
      "Test score for year 2015 : 44.1448275862%\n",
      "Test score for year 2015 : 43.7220338983%\n",
      "Test score for year 2015 : 44.4133333333%\n",
      "Test score for year 2016 : 45.2655737705%\n",
      "Test score for year 2016 : 45.2%\n",
      "Test score for year 2016 : 46.0952380952%\n",
      "Test score for year 2016 : 46.50625%\n",
      "Test score for year 2016 : 46.96%\n",
      "Test score for year 2016 : 48.2666666667%\n",
      "Test score for year 2016 : 47.928358209%\n",
      "Test score for year 2016 : 48.9176470588%\n",
      "Test score for year 2016 : 49.5884057971%\n",
      "Test score for year 2016 : 50.6514285714%\n",
      "Test score for year 2017 : 50.8676056338%\n",
      "Test score for year 2017 : 50.6888888889%\n",
      "Test score for year 2017 : 51.5890410959%\n",
      "Test score for year 2017 : 52.0648648649%\n",
      "Test score for year 2017 : 52.56%\n",
      "Test score for year 2017 : 53.2947368421%\n",
      "Test score for year 2017 : 53.8909090909%\n",
      "Test score for year 2017 : 53.7230769231%\n",
      "Test score for year 2017 : 54.182278481%\n",
      "Test score for year 2017 : 55.175%\n"
     ]
    }
   ],
   "source": [
    "PredictGenerate().set_up_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PredictGenerate():\n",
    "    def __init__(self, algo):\n",
    "        self.years = [2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "        self.sc_X = StandardScaler()\n",
    "        self.onehotencoder = OneHotEncoder(categorical_features=[0, 1])\n",
    "        self.event_dict = {1: 'poverty', 2: 'health_care', 3: 'education', 4: 'donations'}\n",
    "        self.algo = algo\n",
    "        self.model = self.get_basic_model()\n",
    "\n",
    "    def get_basic_model(self):\n",
    "        dataset = pd.read_csv(\"random_dataset_2010.csv\")\n",
    "        X = dataset.iloc[:, [1, 5]].values\n",
    "        y = dataset.iloc[:, 7].values\n",
    "        onehotencoder = OneHotEncoder(categorical_features=[0, 1])\n",
    "        X = onehotencoder.fit_transform(X).toarray()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "        sc_X = StandardScaler()\n",
    "        X_train = sc_X.fit_transform(X_train)\n",
    "        model = self.fit_model(X_train, y_train)\n",
    "        filename = self.algo+\"_model_trained_on_2010.pkl\"\n",
    "        joblib.dump(model, filename)\n",
    "        return model\n",
    "\n",
    "    def set_up_data(self):\n",
    "        for year in self.years:\n",
    "            filename = \"dataset_\" + str(year) + \".csv\"\n",
    "            df = pd.read_csv(filename)\n",
    "            X_data = df.iloc[:, [1, 5]].values\n",
    "            self.make_prediction_data(df, X_data, year)\n",
    "\n",
    "    def make_prediction_data(self, df, X_data, year):\n",
    "        k = 1000\n",
    "        for row in range(0, 10000, k):\n",
    "            x_write = []\n",
    "            X = X_data[row:row + k, :]\n",
    "            for i in xrange(k):\n",
    "                x_write.append(list(df.iloc[i, :].values))\n",
    "\n",
    "            X_encoded = self.encode_data(X)\n",
    "            X_test = self.get_scaled_test_data(X_encoded)\n",
    "            self.predict_data(X_test, x_write, k, year)\n",
    "            self.make_new_model(year)\n",
    "\n",
    "    def predict_data(self, x_test, x_file, k, year):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        for i in range(k):\n",
    "            event = self.event_dict[y_pred[i]]\n",
    "            x_file[i].append(event)\n",
    "            x_file[i].append(y_pred[i])\n",
    "            self.write_to_file(x_file[i], year)\n",
    "\n",
    "    def write_to_file(self, row, year):\n",
    "        filename = self.algo+\"_dataset.csv\"\n",
    "        with open(filename, 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(row)\n",
    "        csvFile.close()\n",
    "\n",
    "    def make_new_model(self, year):\n",
    "        filename = self.algo + \"_dataset.csv\"\n",
    "        dataset = pd.read_csv(filename)\n",
    "        X = dataset.iloc[:, [1, 5]].values\n",
    "        y = dataset.iloc[:, 7].values\n",
    "        X = self.encode_data(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "        X_train, X_test = self.get_scaled_data(X_train, X_test)\n",
    "        self.model = self.fit_model(X_train, y_train)\n",
    "        filename = self.algo+\"_model.pkl\"\n",
    "        joblib.dump(self.model, filename)\n",
    "        score = self.model.score(X_test, y_test)\n",
    "        print(\"Test score for year {} : {}%\".format(year, 100 * score))\n",
    "\n",
    "    def fit_model(self, X_train, y_train):\n",
    "        model = None\n",
    "        if self.algo == \"knn\":\n",
    "            model = KNeighborsClassifier(n_neighbors=8, metric='minkowski', p=2)\n",
    "            model.fit(X_train, y_train)\n",
    "        elif self.algo == \"svm\":\n",
    "            model = SVC(kernel='linear', random_state=0)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        elif self.algo == \"decision_tree\":\n",
    "            model = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        elif self.algo == \"random_forest\":\n",
    "            model = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        elif self.algo == \"nb\":\n",
    "            model = GaussianNB()\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_scaled_test_data(self, X_test):\n",
    "        X_test = self.sc_X.fit_transform(X_test)\n",
    "        return X_test\n",
    "\n",
    "    def get_scaled_data(self, X_train, X_test):\n",
    "        X_train = self.sc_X.fit_transform(X_train)\n",
    "        X_test = self.sc_X.fit_transform(X_test)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def encode_data(self, X):\n",
    "        X = self.onehotencoder.fit_transform(X).toarray()\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : ********\n",
      "Test score for year 2011 : 92.0606060606%\n",
      "Test score for year 2011 : 92.2941176471%\n",
      "Test score for year 2011 : 92.4685714286%\n",
      "Test score for year 2011 : 92.7111111111%\n",
      "Test score for year 2011 : 92.4864864865%\n",
      "Test score for year 2011 : 92.8736842105%\n",
      "Test score for year 2011 : 92.8820512821%\n",
      "Test score for year 2011 : 92.92%\n",
      "Test score for year 2011 : 93.2195121951%\n",
      "Test score for year 2011 : 93.4952380952%\n",
      "Test score for year 2012 : 93.888372093%\n",
      "Test score for year 2012 : 93.7454545455%\n",
      "Test score for year 2012 : 93.9466666667%\n",
      "Test score for year 2012 : 94.0695652174%\n",
      "Test score for year 2012 : 93.9659574468%\n",
      "Test score for year 2012 : 94.4833333333%\n",
      "Test score for year 2012 : 94.4734693878%\n",
      "Test score for year 2012 : 94.84%\n",
      "Test score for year 2012 : 94.8235294118%\n",
      "Test score for year 2012 : 95.0307692308%\n",
      "Test score for year 2013 : 95.0641509434%\n",
      "Test score for year 2013 : 95.0148148148%\n",
      "Test score for year 2013 : 95.1927272727%\n",
      "Test score for year 2013 : 95.4571428571%\n",
      "Test score for year 2013 : 95.298245614%\n",
      "Test score for year 2013 : 95.3586206897%\n",
      "Test score for year 2013 : 95.6%\n",
      "Test score for year 2013 : 95.6133333333%\n",
      "Test score for year 2013 : 95.7967213115%\n",
      "Test score for year 2013 : 95.8516129032%\n",
      "Test score for year 2014 : 95.8603174603%\n",
      "Test score for year 2014 : 95.86875%\n",
      "Test score for year 2014 : 96.0615384615%\n",
      "Test score for year 2014 : 96.096969697%\n",
      "Test score for year 2014 : 96.2268656716%\n",
      "Test score for year 2014 : 96.2941176471%\n",
      "Test score for year 2014 : 96.3768115942%\n",
      "Test score for year 2014 : 96.3942857143%\n",
      "Test score for year 2014 : 96.4338028169%\n",
      "Test score for year 2014 : 96.4666666667%\n",
      "Test score for year 2015 : 96.4547945205%\n",
      "Test score for year 2015 : 96.3945945946%\n",
      "Test score for year 2015 : 96.4106666667%\n",
      "Test score for year 2015 : 96.3947368421%\n",
      "Test score for year 2015 : 96.4935064935%\n",
      "Test score for year 2015 : 96.5794871795%\n",
      "Test score for year 2015 : 96.582278481%\n",
      "Test score for year 2015 : 96.685%\n",
      "Test score for year 2015 : 96.750617284%\n",
      "Test score for year 2015 : 96.7804878049%\n",
      "Test score for year 2016 : 96.7325301205%\n",
      "Test score for year 2016 : 96.7333333333%\n",
      "Test score for year 2016 : 96.8235294118%\n",
      "Test score for year 2016 : 96.8511627907%\n",
      "Test score for year 2016 : 96.9747126437%\n",
      "Test score for year 2016 : 96.8909090909%\n",
      "Test score for year 2016 : 96.808988764%\n",
      "Test score for year 2016 : 96.8355555556%\n",
      "Test score for year 2016 : 96.9186813187%\n",
      "Test score for year 2016 : 96.9782608696%\n",
      "Test score for year 2017 : 96.9505376344%\n",
      "Test score for year 2017 : 97.0340425532%\n",
      "Test score for year 2017 : 97.0694736842%\n",
      "Test score for year 2017 : 97.0541666667%\n",
      "Test score for year 2017 : 97.0804123711%\n",
      "Test score for year 2017 : 97.1632653061%\n",
      "Test score for year 2017 : 97.1232323232%\n",
      "Test score for year 2017 : 97.248%\n",
      "Test score for year 2017 : 97.203960396%\n",
      "Test score for year 2017 : 97.2431372549%\n",
      "Random Forest : ********\n",
      "Test score for year 2011 : 31.1272727273%\n",
      "Test score for year 2011 : 30.0666666667%\n",
      "Test score for year 2011 : 29.4769230769%\n",
      "Test score for year 2011 : 29.9714285714%\n",
      "Test score for year 2011 : 28.4533333333%\n",
      "Test score for year 2011 : 26.5%\n",
      "Test score for year 2011 : 27.2%\n",
      "Test score for year 2011 : 27.5111111111%\n",
      "Test score for year 2011 : 25.9578947368%\n",
      "Test score for year 2011 : 27.64%\n",
      "Test score for year 2012 : 32.0571428571%\n",
      "Test score for year 2012 : 29.2%\n",
      "Test score for year 2012 : 28.3826086957%\n",
      "Test score for year 2012 : 28.1333333333%\n",
      "Test score for year 2012 : 28.704%\n",
      "Test score for year 2012 : 28.3692307692%\n",
      "Test score for year 2012 : 27.8518518519%\n",
      "Test score for year 2012 : 28.3142857143%\n",
      "Test score for year 2012 : 27.875862069%\n",
      "Test score for year 2012 : 27.56%\n",
      "Test score for year 2013 : 30.8387096774%\n",
      "Test score for year 2013 : 30.1875%\n",
      "Test score for year 2013 : 29.0181818182%\n",
      "Test score for year 2013 : 29.6941176471%\n",
      "Test score for year 2013 : 29.3371428571%\n",
      "Test score for year 2013 : 29.0666666667%\n",
      "Test score for year 2013 : 29.3297297297%\n",
      "Test score for year 2013 : 29.3263157895%\n",
      "Test score for year 2013 : 29.158974359%\n",
      "Test score for year 2013 : 29.34%\n",
      "Test score for year 2014 : 30.8487804878%\n",
      "Test score for year 2014 : 30.5714285714%\n",
      "Test score for year 2014 : 30.1023255814%\n",
      "Test score for year 2014 : 30.2636363636%\n",
      "Test score for year 2014 : 29.9377777778%\n",
      "Test score for year 2014 : 29.9739130435%\n",
      "Test score for year 2014 : 29.8382978723%\n",
      "Test score for year 2014 : 29.9583333333%\n",
      "Test score for year 2014 : 30.0897959184%\n",
      "Test score for year 2014 : 29.728%\n",
      "Test score for year 2015 : 31.5921568627%\n",
      "Test score for year 2015 : 31.3461538462%\n",
      "Test score for year 2015 : 31.2830188679%\n",
      "Test score for year 2015 : 30.8074074074%\n",
      "Test score for year 2015 : 30.9090909091%\n",
      "Test score for year 2015 : 30.6071428571%\n",
      "Test score for year 2015 : 31.3824561404%\n",
      "Test score for year 2015 : 30.8344827586%\n",
      "Test score for year 2015 : 30.5559322034%\n",
      "Test score for year 2015 : 30.7666666667%\n",
      "Test score for year 2016 : 31.7901639344%\n",
      "Test score for year 2016 : 31.4580645161%\n",
      "Test score for year 2016 : 31.8158730159%\n",
      "Test score for year 2016 : 31.6%\n",
      "Test score for year 2016 : 32.1230769231%\n",
      "Test score for year 2016 : 32.0121212121%\n",
      "Test score for year 2016 : 31.8626865672%\n",
      "Test score for year 2016 : 31.8823529412%\n",
      "Test score for year 2016 : 32.2492753623%\n",
      "Test score for year 2016 : 31.3714285714%\n",
      "Test score for year 2017 : 33.138028169%\n",
      "Test score for year 2017 : 33.0333333333%\n",
      "Test score for year 2017 : 32.4328767123%\n",
      "Test score for year 2017 : 33.2594594595%\n",
      "Test score for year 2017 : 33.5893333333%\n",
      "Test score for year 2017 : 33.8789473684%\n",
      "Test score for year 2017 : 33.0545454545%\n",
      "Test score for year 2017 : 33.4205128205%\n",
      "Test score for year 2017 : 33.4227848101%\n",
      "Test score for year 2017 : 33.55%\n",
      "Decision Tree : ********\n",
      "Test score for year 2011 : 32.4363636364%\n",
      "Test score for year 2011 : 32.7666666667%\n",
      "Test score for year 2011 : 31.3230769231%\n",
      "Test score for year 2011 : 30.8857142857%\n",
      "Test score for year 2011 : 29.0933333333%\n",
      "Test score for year 2011 : 28.6%\n",
      "Test score for year 2011 : 29.0588235294%\n",
      "Test score for year 2011 : 29.5333333333%\n",
      "Test score for year 2011 : 27.9368421053%\n",
      "Test score for year 2011 : 29.46%\n",
      "Test score for year 2012 : 33.6761904762%\n",
      "Test score for year 2012 : 32.9272727273%\n",
      "Test score for year 2012 : 31.6347826087%\n",
      "Test score for year 2012 : 32.1166666667%\n",
      "Test score for year 2012 : 32.288%\n",
      "Test score for year 2012 : 31.9076923077%\n",
      "Test score for year 2012 : 32.237037037%\n",
      "Test score for year 2012 : 33.2428571429%\n",
      "Test score for year 2012 : 33.724137931%\n",
      "Test score for year 2012 : 33.3466666667%\n",
      "Test score for year 2013 : 35.9483870968%\n",
      "Test score for year 2013 : 35.675%\n",
      "Test score for year 2013 : 35.7818181818%\n",
      "Test score for year 2013 : 36.2588235294%\n",
      "Test score for year 2013 : 36.5142857143%\n",
      "Test score for year 2013 : 37.5888888889%\n",
      "Test score for year 2013 : 38.2378378378%\n",
      "Test score for year 2013 : 39.4421052632%\n",
      "Test score for year 2013 : 39.9282051282%\n",
      "Test score for year 2013 : 40.69%\n",
      "Test score for year 2014 : 42.312195122%\n",
      "Test score for year 2014 : 42.7142857143%\n",
      "Test score for year 2014 : 44.0279069767%\n",
      "Test score for year 2014 : 44.0636363636%\n",
      "Test score for year 2014 : 44.8355555556%\n",
      "Test score for year 2014 : 45.9739130435%\n",
      "Test score for year 2014 : 46.8765957447%\n",
      "Test score for year 2014 : 47.0916666667%\n",
      "Test score for year 2014 : 48.0081632653%\n",
      "Test score for year 2014 : 48.592%\n",
      "Test score for year 2015 : 49.4117647059%\n",
      "Test score for year 2015 : 50.3692307692%\n",
      "Test score for year 2015 : 50.9962264151%\n",
      "Test score for year 2015 : 51.6296296296%\n",
      "Test score for year 2015 : 52.48%\n",
      "Test score for year 2015 : 53.2571428571%\n",
      "Test score for year 2015 : 54.1263157895%\n",
      "Test score for year 2015 : 54.7103448276%\n",
      "Test score for year 2015 : 55.5322033898%\n",
      "Test score for year 2015 : 56.1933333333%\n",
      "Test score for year 2016 : 56.6754098361%\n",
      "Test score for year 2016 : 57.6064516129%\n",
      "Test score for year 2016 : 57.9936507937%\n",
      "Test score for year 2016 : 59.3125%\n",
      "Test score for year 2016 : 59.3230769231%\n",
      "Test score for year 2016 : 59.8%\n",
      "Test score for year 2016 : 60.6208955224%\n",
      "Test score for year 2016 : 61.6882352941%\n",
      "Test score for year 2016 : 61.8028985507%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for year 2016 : 62.5485714286%\n",
      "Test score for year 2017 : 62.8732394366%\n",
      "Test score for year 2017 : 63.3555555556%\n",
      "Test score for year 2017 : 63.6328767123%\n",
      "Test score for year 2017 : 64.2486486486%\n",
      "Test score for year 2017 : 64.4906666667%\n",
      "Test score for year 2017 : 65.5631578947%\n",
      "Test score for year 2017 : 66.0675324675%\n",
      "Test score for year 2017 : 66.3538461538%\n",
      "Test score for year 2017 : 66.6734177215%\n",
      "Test score for year 2017 : 67.285%\n",
      "Naive Bayes : ********\n",
      "Test score for year 2011 : 35.2363636364%\n",
      "Test score for year 2011 : 35.7666666667%\n",
      "Test score for year 2011 : 33.2923076923%\n",
      "Test score for year 2011 : 31.5714285714%\n",
      "Test score for year 2011 : 30.8533333333%\n",
      "Test score for year 2011 : 30.375%\n",
      "Test score for year 2011 : 30.2352941176%\n",
      "Test score for year 2011 : 29.3555555556%\n",
      "Test score for year 2011 : 29.5578947368%\n",
      "Test score for year 2011 : 28.92%\n",
      "Test score for year 2012 : 33.6761904762%\n",
      "Test score for year 2012 : 33.4363636364%\n",
      "Test score for year 2012 : 32.2086956522%\n",
      "Test score for year 2012 : 32.05%\n",
      "Test score for year 2012 : 32.288%\n",
      "Test score for year 2012 : 32.1230769231%\n",
      "Test score for year 2012 : 30.962962963%\n",
      "Test score for year 2012 : 31.4857142857%\n",
      "Test score for year 2012 : 31.8206896552%\n",
      "Test score for year 2012 : 30.6266666667%\n",
      "Test score for year 2013 : 33.3032258065%\n",
      "Test score for year 2013 : 33.1625%\n",
      "Test score for year 2013 : 32.7151515152%\n",
      "Test score for year 2013 : 33.3764705882%\n",
      "Test score for year 2013 : 31.9542857143%\n",
      "Test score for year 2013 : 31.9888888889%\n",
      "Test score for year 2013 : 31.8162162162%\n",
      "Test score for year 2013 : 31.9368421053%\n",
      "Test score for year 2013 : 31.8564102564%\n",
      "Test score for year 2013 : 31.06%\n",
      "Test score for year 2014 : 32.9756097561%\n",
      "Test score for year 2014 : 33.1904761905%\n",
      "Test score for year 2014 : 32.111627907%\n",
      "Test score for year 2014 : 32.5272727273%\n",
      "Test score for year 2014 : 32.2044444444%\n",
      "Test score for year 2014 : 32.3391304348%\n",
      "Test score for year 2014 : 32.6553191489%\n",
      "Test score for year 2014 : 32.1333333333%\n",
      "Test score for year 2014 : 32.0571428571%\n",
      "Test score for year 2014 : 31.624%\n",
      "Test score for year 2015 : 32.4862745098%\n",
      "Test score for year 2015 : 32.7538461538%\n",
      "Test score for year 2015 : 32.5358490566%\n",
      "Test score for year 2015 : 32.4518518519%\n",
      "Test score for year 2015 : 32.4727272727%\n",
      "Test score for year 2015 : 31.8714285714%\n",
      "Test score for year 2015 : 32.0%\n",
      "Test score for year 2015 : 32.5172413793%\n",
      "Test score for year 2015 : 31.8644067797%\n",
      "Test score for year 2015 : 31.8866666667%\n",
      "Test score for year 2016 : 33.0557377049%\n",
      "Test score for year 2016 : 32.9935483871%\n",
      "Test score for year 2016 : 32.4761904762%\n",
      "Test score for year 2016 : 32.35%\n",
      "Test score for year 2016 : 32.6276923077%\n",
      "Test score for year 2016 : 32.2727272727%\n",
      "Test score for year 2016 : 31.6119402985%\n",
      "Test score for year 2016 : 32.3411764706%\n",
      "Test score for year 2016 : 32.2492753623%\n",
      "Test score for year 2016 : 31.9771428571%\n",
      "Test score for year 2017 : 32.6309859155%\n",
      "Test score for year 2017 : 32.6944444444%\n",
      "Test score for year 2017 : 32.2684931507%\n",
      "Test score for year 2017 : 32.627027027%\n",
      "Test score for year 2017 : 32.8%\n",
      "Test score for year 2017 : 32.5105263158%\n",
      "Test score for year 2017 : 32.0363636364%\n",
      "Test score for year 2017 : 32.2615384615%\n",
      "Test score for year 2017 : 31.6759493671%\n",
      "Test score for year 2017 : 32.04%\n"
     ]
    }
   ],
   "source": [
    "# print \"KNN : ********\"\n",
    "# PredictGenerate().set_up_data(\"knn\")\n",
    "\n",
    "\n",
    "print \"SVM : ********\"\n",
    "PredictGenerate(\"svm\").set_up_data()\n",
    "\n",
    "print \"Random Forest : ********\"\n",
    "PredictGenerate(\"random_forest\").set_up_data()\n",
    "\n",
    "print \"Decision Tree : ********\"\n",
    "PredictGenerate(\"decision_tree\").set_up_data()\n",
    "\n",
    "print \"Naive Bayes : ********\"\n",
    "PredictGenerate(\"nb\").set_up_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
